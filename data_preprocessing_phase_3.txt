@startuml Phase 3 - Full Metadata Conditioning

!define PHASE2 #FFF9C4
!define PHASE3 #E1BEE7

' ===============================================================================
' Phase 2 Classes (inherited/reused)
' ===============================================================================

package "Phase 2 (Reused)" PHASE2 {
  class ConditionalEncodingConfig {
    +mode: str
    +use_label_conditioning: bool
    +label_embedding_dim: int
    +label_conditioning_type: str
    --
    +save()
    +load()
  }

  class MusicSample {
    +id: str
    +music: muspy.Music
    +labels: List[int]
    +primary_label: int
    +gigamidi_metadata: Dict
    +metadata: Dict
    --
    +to_hdf5()
    +from_hdf5()
  }

  class MusicSampleDataset {
    +hdf5_path: str
    --
    +__getitem__(idx: int): MusicSample
  }

  class LabelConditioner {
    +encode_multi_label(labels: List[int]): np.ndarray
  }

  class MIDIEncoder {
    +encode(sample: MusicSample): np.ndarray
  }

  class Segmenter {
    +segment(tokens: np.ndarray): List[np.ndarray]
  }
}

' ===============================================================================
' Phase 3: Enhanced Configuration
' ===============================================================================

package "Phase 3: Configuration" PHASE3 {
  class FullConditionalConfig {
    ' Inherits from ConditionalEncodingConfig
    +conditioning_features: List[str]
    +use_tempo: bool
    +use_note_density: bool
    +use_instruments: bool
    +use_drums_flag: bool
    +use_velocity_stats: bool
    +use_loop_info: bool
    +use_num_tracks: bool
    +use_time_signature: bool
    +conditioning_vector_dim: int
    +normalize_features: bool
    --
    +get_enabled_features(): List[str]
    +save()
    +load()
    +validate_config(): bool
  }

  note right of FullConditionalConfig
    **Feature Categories:**
    
    **Numerical (normalized):**
    - tempo [0, 1]
    - note_density [0, 1]
    - avg_velocity [0, 1]
    - duration_beats [0, 1]
    
    **Categorical (one-hot):**
    - time_signature
    - num_tracks (binned)
    
    **Binary:**
    - has_drums {0, 1}
    - is_drums_only {0, 1}
    
    **Multi-hot:**
    - instrument_programs
    - labels (from Phase 2)
    
    **Conditional vector:**
    Concatenation of all enabled features
  end note
}

' ===============================================================================
' Phase 3: Feature Extraction
' ===============================================================================

package "Phase 3: Feature Extraction" PHASE3 {
  class ConditioningFeatureExtractor {
    +config: FullConditionalConfig
    --
    +extract_from_gigamidi(gigamidi_meta: Dict): Dict
    +extract_from_music(music: muspy.Music): Dict
    +extract_tempo(music: muspy.Music, gigamidi_meta: Dict): float
    +extract_note_density(music: muspy.Music, gigamidi_meta: Dict): float
    +extract_velocity_stats(music: muspy.Music, gigamidi_meta: Dict): Dict
    +extract_instrument_programs(music: muspy.Music, gigamidi_meta: Dict): List[int]
    +extract_loop_features(gigamidi_meta: Dict): Optional[Dict]
    +extract_time_signature(music: muspy.Music): str
    +extract_num_tracks(music: muspy.Music): int
    +combine_features(gigamidi_features: Dict, music_features: Dict): Dict
    +validate_features(features: Dict): bool
  }

  note right of ConditioningFeatureExtractor
    **Priority:**
    1. Use gigamidi_metadata (when available)
    2. Fall back to muspy.Music computation
    
    **Example:**
    tempo = gigamidi_meta.get('tempo') or 
            compute_tempo(music)
    
    Ensures consistency and speed
  end note
}

' ===============================================================================
' Phase 3: Metadata Encoding
' ===============================================================================

package "Phase 3: Metadata Encoding" PHASE3 {
  class MetadataEncoder {
    +config: FullConditionalConfig
    +label_conditioner: LabelConditioner
    +numerical_features: List[str]
    +categorical_features: List[str]
    +binary_features: List[str]
    +feature_stats: Dict
    +instrument_vocab: Dict[int, int]
    +time_signature_vocab: Dict[str, int]
    --
    +fit(samples: List[MusicSample])
    +compute_statistics(samples: List[MusicSample]): Dict
    +normalize_numerical(feature: str, value: float): float
    +encode_tempo(tempo: float): float
    +encode_note_density(density: float): float
    +encode_velocity_stats(stats: Dict): np.ndarray
    +encode_instrument_programs(programs: List[int]): np.ndarray
    +encode_time_signature(time_sig: str): np.ndarray
    +encode_num_tracks(num_tracks: int): np.ndarray
    +encode_binary_flags(has_drums: bool, is_drums_only: bool): np.ndarray
    +encode_loop_features(loop_info: Dict): np.ndarray
    +encode_all(features: Dict, labels: List[int]): np.ndarray
    +get_feature_dimensions(): Dict[str, int]
    +save(path: str)
    +load(path: str)
  }

  note right of MetadataEncoder
    **Normalization Strategy:**
    
    **Min-Max (0-1):**
    - tempo: [40, 240] → [0, 1]
    - note_density: [0, 20] → [0, 1]
    - velocity: [0, 127] → [0, 1]
    
    **Z-score (mean=0, std=1):**
    - duration_beats
    
    **One-hot:**
    - time_signature: 4/4, 3/4, etc.
    
    **Multi-hot:**
    - instruments: [piano, guitar, drums]
      → [1, 0, 1, 0, ..., 1]
    
    **Feature vector assembly:**
    [labels | tempo | density | velocity | 
     has_drums | instruments | time_sig | ...]
  end note

  class FeatureStatistics {
    +feature_mins: Dict[str, float]
    +feature_maxs: Dict[str, float]
    +feature_means: Dict[str, float]
    +feature_stds: Dict[str, float]
    +instrument_counts: Dict[int, int]
    +time_signature_counts: Dict[str, int]
    --
    +to_dict(): Dict
    +from_dict(data: Dict)
  }

  MetadataEncoder *-- FeatureStatistics
}

' ===============================================================================
' Phase 3: Modified Data Structures
' ===============================================================================

package "Phase 3: Data Structures" PHASE3 {
  class EncodedSample_V3 {
    ' All fields from Phase 2
    +id: str
    +tokens: np.ndarray
    +drum_tokens: Optional[np.ndarray]
    +labels: List[int]
    +primary_label: int
    +original_id: str
    +label_conditioning: np.ndarray
    --
    ' NEW in Phase 3
    +conditioning_vector: np.ndarray
    +conditioning_features: Dict
    --
    +sequence_length: int
    +conditioning_dim: int
    --
    +to_hdf5(group: h5py.Group)
    +from_hdf5(group: h5py.Group): EncodedSample_V3
    +get_full_conditioning(): np.ndarray
    +get_feature(feature_name: str): Any
  }

  note right of EncodedSample_V3
    **conditioning_vector:**
    Full concatenated feature vector
    Shape: [conditioning_vector_dim]
    
    **conditioning_features:**
    Raw features for inspection:
    {
      'tempo': 120.0,
      'note_density': 2.5,
      'has_drums': True,
      'instruments': [0, 33, 128],
      'time_signature': '4/4',
      ...
    }
    
    Both stored in HDF5 for:
    - Fast training (vector)
    - Analysis/debugging (raw features)
  end note
}

' ===============================================================================
' Phase 3: Modified Processors
' ===============================================================================

package "Phase 3: Processing Pipeline" PHASE3 {
  class MusicSampleProcessor_V3 {
    ' Inherits from Phase 1
    +config: PreprocessingConfig
    +feature_extractor: ConditioningFeatureExtractor
    --
    +process_single_sample(sample_dict: Dict): Optional[MusicSample]
    +extract_and_store_features(sample_dict: Dict, music: muspy.Music): Dict
  }

  class EncodedSampleProcessor_V3 {
    +config: FullConditionalConfig
    +encoder: MIDIEncoder
    +segmenter: Segmenter
    +augmenter_v3: Augmenter_V3
    +metadata_encoder: MetadataEncoder
    +feature_extractor: ConditioningFeatureExtractor
    +output_dir: str
    --
    +fit_metadata_encoder(samples: List[MusicSample])
    +process_single_sample(sample: MusicSample): List[EncodedSample_V3]
    +encode_conditioning(sample: MusicSample): Tuple[np.ndarray, Dict]
    +process_dataset(input_path: str): List[EncodedSample_V3]
    +split_train_val_test(samples: List[EncodedSample_V3]): Dict
    +save_to_hdf5(samples: Dict[str, List[EncodedSample_V3]], output_dir: str)
  }

  class EncodedSampleDataset_V3 {
    +train_path: str
    +val_path: str
    +test_path: str
    +config: FullConditionalConfig
    +metadata_encoder: MetadataEncoder
    +_file_handles: Dict[str, h5py.File]
    --
    +load_split(split: str): h5py.File
    +__len__(split: str): int
    +__getitem__(split: str, idx: int): Tuple[np.ndarray, np.ndarray, List[int]]
    +get_conditioning_batch(split: str, indices: List[int]): np.ndarray
    +get_feature_batch(split: str, indices: List[int], feature: str): np.ndarray
    +close()
  }

  note right of EncodedSampleDataset_V3
    **Returns:**
    (tokens, conditioning_vector, labels)
    
    - tokens: [seq_len]
    - conditioning_vector: [cond_dim]
    - labels: [num_labels]
    
    **cond_dim breakdown example:**
    - labels: 50 (multi-hot)
    - tempo: 1
    - note_density: 1
    - velocity: 3 (min, avg, max)
    - has_drums: 1
    - instruments: 128 (multi-hot)
    - time_signature: 10 (one-hot)
    - num_tracks: 5 (binned one-hot)
    **Total: ~199 dimensions**
  end note

  class Augmenter_V3 {
    +config: FullConditionalConfig
    +feature_extractor: ConditioningFeatureExtractor
    --
    +pitch_shift(music: muspy.Music, semitones: int): muspy.Music
    +tempo_change(music: muspy.Music, factor: float): muspy.Music
    +augment_drums(music: muspy.Music): muspy.Music
    +augment(sample: MusicSample): List[MusicSample]
    +recompute_conditioning_features(augmented_music: muspy.Music, original_features: Dict, augmentation_type: str): Dict
  }

  note right of Augmenter_V3
    **Conditioning update for augmentation:**
    
    **Pitch shift:**
    - instrument_programs: May change
    - Recompute from augmented music
    
    **Tempo change:**
    - tempo: Multiply by factor
    - note_density: May change slightly
    - Update directly without recompute
    
    **Drums augmentation:**
    - velocity stats: Recompute
    - Other features: Unchanged
    
    Ensures conditioning matches augmented music
  end note
}

' ===============================================================================
' Relationships
' ===============================================================================

' Inheritance
FullConditionalConfig --|> ConditionalEncodingConfig
EncodedSample_V3 --|> "Phase 2::EncodedSample_V2"
MusicSampleProcessor_V3 --|> "Phase 1::MusicSampleProcessor"
EncodedSampleProcessor_V3 --|> "Phase 2::EncodedSampleProcessor_V2"
EncodedSampleDataset_V3 --|> "Phase 2::EncodedSampleDataset_V2"
Augmenter_V3 --|> "Phase 1::Augmenter"

' Composition
FullConditionalConfig -- EncodedSampleProcessor_V3
FullConditionalConfig -- ConditioningFeatureExtractor
FullConditionalConfig -- MetadataEncoder

MetadataEncoder -- EncodedSampleProcessor_V3
MetadataEncoder -- EncodedSampleDataset_V3
ConditioningFeatureExtractor -- MusicSampleProcessor_V3
ConditioningFeatureExtractor -- EncodedSampleProcessor_V3
ConditioningFeatureExtractor -- Augmenter_V3

LabelConditioner -- MetadataEncoder
MIDIEncoder -- EncodedSampleProcessor_V3
Segmenter -- EncodedSampleProcessor_V3
Augmenter_V3 -- EncodedSampleProcessor_V3

' Data flow
MusicSampleDataset --> EncodedSampleProcessor_V3 : provides
EncodedSampleProcessor_V3 --> EncodedSample_V3 : creates
EncodedSampleProcessor_V3 --> EncodedSampleDataset_V3 : saves to
EncodedSampleDataset_V3 --> EncodedSample_V3 : loads

' ===============================================================================
' Notes
' ===============================================================================

note top of FullConditionalConfig
  **Enables fine-grained control**
  
  Select which metadata features to use:
  - All features: Maximum control
  - Subset: Balance control vs complexity
  - Just labels: Falls back to Phase 2
  
  **Backward compatible:**
  Can disable all metadata features
  to behave like Phase 2
end note

note bottom of EncodedSampleProcessor_V3
  **Modified Pipeline:**
  1. **NEW: Fit MetadataEncoder on train set**
  2. Load MusicSample
  3. Augment (with feature updates)
  4. Encode to tokens
  5. **NEW: Extract conditioning features**
  6. **NEW: Encode to conditioning vector**
  7. Segment
  8. Create EncodedSample_V3
  9. Split train/val/test
  10. Save to HDF5
  
  **Key addition:**
  MetadataEncoder must be fit on training
  data before encoding validation/test sets
end note

note as StorageNote
  **HDF5 Storage (Phase 3):**
  
  data/encoded_samples/genre_mode_full/
  ├── train.h5
  │   ├── tokens [N, seq_len]
  │   ├── conditioning_vectors [N, cond_dim]
  │   ├── labels [N, num_labels]
  │   └── features/  # Raw for inspection
  │       ├── tempo [N]
  │       ├── note_density [N]
  │       ├── instruments [N, max_instruments]
  │       └── ...
  ├── val.h5
  ├── test.h5
  ├── encoding_config.json
  ├── metadata_encoder.pkl
  └── feature_statistics.json
  
  **Storage increase: ~15-20%**
  (conditioning vectors + raw features)
end note

note as UsageNote
  **Model Training (Phase 3):**
```python
  for batch in dataloader:
      tokens, conditioning, labels = batch
      # tokens: [B, seq_len]
      # conditioning: [B, cond_dim]
      # labels: [B, num_labels]
      
      logits = model(tokens, conditioning=conditioning)
      loss = criterion(logits, labels)
```
  
  **Generation with full control:**
```python
  # Specify exact characteristics
  conditioning = metadata_encoder.encode_all(
      features={
          'tempo': 120.0,
          'note_density': 2.5,
          'has_drums': True,
          'instruments': [0, 33, 128],  # piano, bass, drums
          'time_signature': '4/4',
          'num_tracks': 3
      },
      labels=[label_encoder.encode("stoner_rock")]
  )
  generated = model.generate(conditioning=conditioning)
  
  # Interpolate between two songs
  cond1 = sample1.conditioning_vector
  cond2 = sample2.conditioning_vector
  cond_interp = 0.7 * cond1 + 0.3 * cond2
  generated = model.generate(conditioning=cond_interp)
```
end note

note as AnalysisNote
  **Feature Analysis (Phase 3):**
```python
  # Analyze what features matter most
  dataset = EncodedSampleDataset_V3(...)
  
  # Get all tempos in rock vs classical
  rock_samples = dataset.get_samples_by_label("rock")
  rock_tempos = [s.conditioning_features['tempo'] 
                 for s in rock_samples]
  
  # Compare instrument usage
  rock_instruments = [s.conditioning_features['instruments']
                      for s in rock_samples]
  
  # Feature importance for generation quality
  features = dataset.get_feature_batch('train', 
                                       indices, 
                                       'note_density')
```
end note

@enduml
